{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMErfu7sMZ4TtMgLnBiFU+G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dellainey/Predict-Customer-Churn/blob/master/Predict_customer_churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE2Pbay3-DpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TAdKiua-PQf",
        "colab_type": "text"
      },
      "source": [
        "**Customer Churn** can be defined as the loss of customers or clients. **Customer attrition** and **customer turnover** are some of the other terms that are used and mean the same. This is one of the metrics used by organizations to measure their performance. Losing a customer is a big concern for organizations as the efforts in retaining a customer is much less than obtaining a new customer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pryAgeZ6-bhX",
        "colab_type": "text"
      },
      "source": [
        "The objective of this project is to **predict the customer churn** and thus alert the concerned to take appropriate customer retention initiative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F72feHOJ-kK6",
        "colab_type": "text"
      },
      "source": [
        "# **DATASET:**\n",
        "To perform this task, we will consider the dataset provided by KKBOX (Asia's leading music streaming service) for the WSDM challenge available on kaggle https://www.kaggle.com/c/kkbox-churn-prediction-challenge Note that you have to accept and agree to the rules of the competition to use the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtSyCsvz3gFC",
        "colab_type": "text"
      },
      "source": [
        "The following steps involve reading in the data tables. \n",
        "Since the size of the dataset is 30+ GB, we will randomly select a few users in the train data and trim the other tables so as to keep the data pertaining to only the selected customers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LVcXuB3-s2t",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKZ2fRE3-uEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd5EU5ixBDes",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "5f9460ad-58a9-405e-fc40-959c4d543ef3"
      },
      "source": [
        "# 5 steps to loading a dataset from kaggle\n",
        "# Thanks to Filemon for his post (https://www.kaggle.com/general/74235) on kaggle to do this. Saved me alot of time.\n",
        "\n",
        "#Step -1\n",
        "! pip install -q kaggle\n",
        "\n",
        "# installing the updated version \n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "\n",
        "#Step -2\n",
        "from google.colab import files\n",
        "files.upload()    # a prompt will appear, locate the kaggle.json file that you downloaded\n",
        "\n",
        "#Step -3\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "#Step -4\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "#Step -5\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/bb20f9b9e24f9a6250f95a432f8d9a7d745f8d24039d7a5a6eaadb7783ba/kaggle-1.5.6.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-cp36-none-any.whl size=72859 sha256=1cdaa45db5352641d000464f22ad7be381bfb8501a9f29a8088736dd03188c71\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/4e/e8/bb28d035162fb8f17f8ca5d42c3230e284c6aa565b42b72674\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.6\n",
            "    Uninstalling kaggle-1.5.6:\n",
            "      Successfully uninstalled kaggle-1.5.6\n",
            "Successfully installed kaggle-1.5.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-332d0fc3-2899-4df6-967b-568708fd9a7b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-332d0fc3-2899-4df6-967b-568708fd9a7b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrmfFfurBwk4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "326970e7-6030-4823-fa34-3a5763f7231b"
      },
      "source": [
        "#sanity check\n",
        "! kaggle datasets list"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ref                                                               title                                              size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "----------------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "Cornell-University/arxiv                                          arXiv Dataset                                     877MB  2020-08-14 23:50:57           1779        417  0.875            \n",
            "agirlcoding/all-space-missions-from-1957                          All Space Missions from 1957                      101KB  2020-08-13 16:18:58            805         92  0.85294116       \n",
            "landlord/handwriting-recognition                                  Handwriting Recognition                             1GB  2020-08-05 17:20:36            266         50  0.9411765        \n",
            "jmmvutu/summer-products-and-sales-in-ecommerce-wish               Sales of summer clothes in E-commerce Wish        351KB  2020-08-06 22:27:25            754         37  0.9705882        \n",
            "andrewmvd/heart-failure-clinical-data                             Heart Failure Prediction                            4KB  2020-06-20 01:03:20           1762        125  1.0              \n",
            "martj42/womens-international-football-results                     Women's International Football Results             52KB  2020-08-14 13:24:15            181         16  1.0              \n",
            "vikasojha98/top-women-chess-players                               Top Women Chess Players                           182KB  2020-08-04 16:17:14            171         15  1.0              \n",
            "andrewmvd/hard-hat-detection                                      Safety Helmet Detection                             1GB  2020-08-11 07:40:12             92         45  0.875            \n",
            "andrewmvd/doom-crossing                                           Doom or Animal Crossing? (Image Classification)   997MB  2020-06-04 19:31:08             35         15  0.9411765        \n",
            "ashwinik/consumer-complaints-financial-products                   Consumer Complaints - Financial products           59MB  2020-08-02 16:36:33            214         11  0.7352941        \n",
            "jacobbaruch/basketball-players-stats-per-season-49-leagues        Basketball Players Stats per Season - 49 Leagues    2MB  2020-08-15 20:54:02            212         14  1.0              \n",
            "gpreda/unemployment-in-european-union                             Unemployment in European Union                    874KB  2020-08-12 20:28:46            240         15  1.0              \n",
            "gpreda/covid19-tweets                                             COVID19 Tweets                                     26MB  2020-08-22 11:16:29           2929        248  1.0              \n",
            "ahsen1330/us-police-shootings                                     US Police Shootings                               126KB  2020-07-30 04:23:34           1816        109  0.9705882        \n",
            "vidyapb/indian-school-education-statistics                        Indian School Education Statistics                 24KB  2020-07-23 17:26:11           1588         83  1.0              \n",
            "christianlillelund/passenger-list-for-the-estonia-ferry-disaster  The Estonia Disaster Passenger List                14KB  2020-07-26 15:40:17            755         88  1.0              \n",
            "futurecorporation/epitope-prediction                              COVID-19/SARS B-cell Epitope Prediction             1MB  2020-07-24 02:53:28            716         74  1.0              \n",
            "google/tinyquickdraw                                              QuickDraw Sketches                                 11GB  2018-04-18 19:38:04           2214        224  0.8125           \n",
            "datasnaek/youtube-new                                             Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         101821       2749  0.7941176        \n",
            "zynicide/wine-reviews                                             Wine Reviews                                       51MB  2017-11-27 17:08:04         109989       2499  0.7941176        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF9o33A7CdTa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "447fcd38-44cb-41f6-a033-c7aa69c87705"
      },
      "source": [
        "# copy the API command from the kaggle dataset\n",
        "!kaggle competitions download -c kkbox-churn-prediction-challenge"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading kkbox-churn-prediction-challenge.zip to /content\n",
            "100% 8.32G/8.34G [02:10<00:00, 61.3MB/s]\n",
            "100% 8.34G/8.34G [02:10<00:00, 68.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMq5L76WMNak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "58804b49-602e-4cee-f351-01c09d7da0b0"
      },
      "source": [
        "# making a directory for the main folder and unzipping its content\n",
        "! mkdir kkbox-churn-prediction-challenge\n",
        "! unzip kkbox-churn-prediction-challenge.zip -d kkbox-churn-prediction-challenge"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  kkbox-churn-prediction-challenge.zip\n",
            "  inflating: kkbox-churn-prediction-challenge/WSDMChurnLabeller.scala  \n",
            "  inflating: kkbox-churn-prediction-challenge/members_v3.csv.7z  \n",
            "  inflating: kkbox-churn-prediction-challenge/sample_submission_v2.csv.7z  \n",
            "  inflating: kkbox-churn-prediction-challenge/sample_submission_zero.csv.7z  \n",
            "  inflating: kkbox-churn-prediction-challenge/train.csv.7z  \n",
            "  inflating: kkbox-churn-prediction-challenge/train_v2.csv.7z  \n",
            "  inflating: kkbox-churn-prediction-challenge/transactions.csv.7z  \n",
            "  inflating: kkbox-churn-prediction-challenge/transactions_v2.csv.7z  \n",
            "  inflating: kkbox-churn-prediction-challenge/user_logs.csv.7z  \n",
            "  inflating: kkbox-churn-prediction-challenge/user_logs_v2.csv.7z  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRM7svKjDOi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a directory to save the zipped content\n",
        "# dont have to make directory if the format is .7z\n",
        "# ! mkdir kkbox-churn-prediction-challenge/transactions_v2\n",
        "# ! mkdir kkbox-churn-prediction-challenge/sample_submission_zero\n",
        "# ! mkdir kkbox-churn-prediction-challenge/transactions\n",
        "# ! mkdir kkbox-churn-prediction-challenge/user_logs_v2\n",
        "# ! mkdir kkbox-churn-prediction-challenge/sample_submission_v2\n",
        "# ! mkdir kkbox-churn-prediction-challenge/train_v2\n",
        "# ! mkdir kkbox-churn-prediction-challenge/train\n",
        "# ! mkdir kkbox-churn-prediction-challenge/members_v3\n",
        "# ! mkdir kkbox-churn-prediction-challenge/user_logs"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWj0qe3OVcEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "7aa1b0c0-dd11-4867-bb27-e1fe8fc111da"
      },
      "source": [
        "# unzipping the contents\n",
        "\n",
        "# If the file was just a .zip file, you would use the below comment to unzip and save in the directory\n",
        "#! unzip kkbox-churn-prediction-challenge/transactions_v2.csv.7z -d transactions_v2\n",
        "\n",
        "#Since the files are formated with .7z, we follow the below command to unzip\n",
        "! 7z e kkbox-churn-prediction-challenge/transactions_v2.csv.7z\n",
        "! 7z e kkbox-churn-prediction-challenge/sample_submission_zero.csv.7z\n",
        "! 7z e kkbox-churn-prediction-challenge/transactions.csv.7z\n",
        "! 7z e kkbox-churn-prediction-challenge/user_logs_v2.csv.7z\n",
        "! 7z e kkbox-churn-prediction-challenge/sample_submission_v2.csv.7z\n",
        "! 7z e kkbox-churn-prediction-challenge/train_v2.csv.7z\n",
        "! 7z e kkbox-churn-prediction-challenge/train.csv.7z\n",
        "! 7z e kkbox-churn-prediction-challenge/members_v3.csv.7z\n",
        "! 7z e kkbox-churn-prediction-challenge/user_logs.csv.7z"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 33563098 bytes (33 MiB)\n",
            "\n",
            "Extracting archive: kkbox-churn-prediction-challenge/train.csv.7z\n",
            "--\n",
            "Path = kkbox-churn-prediction-challenge/train.csv.7z\n",
            "Type = 7z\n",
            "Physical Size = 33563098\n",
            "Headers Size = 122\n",
            "Method = LZMA2:24\n",
            "Solid = -\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b\n",
            "Would you like to replace the existing file:\n",
            "  Path:     ./train.csv\n",
            "  Size:     21690 bytes (22 KiB)\n",
            "  Modified: 2020-08-23 19:21:06\n",
            "with the file from archive:\n",
            "  Path:     train.csv\n",
            "  Size:     46667771 bytes (45 MiB)\n",
            "  Modified: 2017-09-14 18:23:03\n",
            "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? y\n",
            "\n",
            "  6% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Size:       46667771\n",
            "Compressed: 33563098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvQSPDka-30R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is another method to load the data from your local disk.\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()       #It will prompt to choose the file location\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36e7MqR6Ljam",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "333aeff0-4f94-463b-a1fe-cf41aaebb8fe"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "train.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(992931, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYoDI2Twf4Bw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4d9f1826-73ea-4a56-909a-ba3a2aca9d43"
      },
      "source": [
        "# Since the dataset is too large, let us first work with a small section.\n",
        "# Once you feel the algorithm works well then we can include all the data\n",
        "train_1 = train[train['is_churn']==0].reset_index(drop = True)\n",
        "rv_1 = np.random.rand(train_1.shape[0])\n",
        "train_2 = train[train['is_churn']==1].reset_index(drop = True)\n",
        "rv_2 = np.random.rand(train_2.shape[0])\n",
        "train_1 = train_1.loc[rv_1<0.02]\n",
        "print(train_1.shape)\n",
        "train_2 = train_2.loc[rv_2<0.02]\n",
        "print(train_2.shape)\n",
        "train = pd.concat([train_1, train_2], ignore_index=True)\n",
        "train.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18705, 2)\n",
            "(1273, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19978, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQe9i2MRh176",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea17b7b1-39cb-4624-ade8-121867d8cbda"
      },
      "source": [
        "# Let us see how many customer churn and how many dont in this smaller dataset\n",
        "print(train[train['is_churn']==0].shape)\n",
        "train[train['is_churn']==1].shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18705, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PP4DtalAERt",
        "colab_type": "text"
      },
      "source": [
        "Once you disconnect, all your data will be lost when you come back to work on this project, as colab wipes itself off. Hence it would be wise to store your inprocess data on your google drive (as shown below) or on your local disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrxlF8jOGCTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copying the newly created train dataset to the google drive \n",
        "# you will need to give access to your google file system\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/drive')\n",
        "# train.to_csv('/drive/My Drive/Colab_datasets/Churn_prediction/train.csv')\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGOAKICwL29p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ddddd8e6-b1d3-400b-a6dc-a924ef931d5f"
      },
      "source": [
        "# Here we save a copy of the smaller trainset on our local drive\n",
        "from google.colab import files\n",
        "train.to_csv('train.csv') \n",
        "files.download('train.csv')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_feef9439-e6bf-4a3b-bdee-b38564668a04\", \"train.csv\", 1047739)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhjtGdxeNEpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b59ed0c-3368-4b63-d179-890d7ba32ef5"
      },
      "source": [
        "msno = train['msno'].to_list()    #'msno' stores the list of customers we will use in our model\n",
        "len(msno)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf-B_eFThs5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us now extract data pertaining to only these users from the rest of the tables and save them to the local disk for processing\n",
        "transactions = pd.read_csv('transactions.csv')\n",
        "user_logs = pd.read_csv('user_logs.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MxaaxNNNVOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1836b125-7de8-471e-c80d-49ee722b3417"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "# Let us now extract data pertaining to only these users from the rest of the tables and save them to the local disk for processing\n",
        "n = 100  # every 100th line = 1% of the lines\n",
        "\n",
        "user_logs = pd.read_csv('user_logs.csv', header=0, skiprows=lambda i: i % n != 0)\n",
        "user_logs.shape"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3921065, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAi4yniFCdRm",
        "colab_type": "text"
      },
      "source": [
        "Colab free version provides you only 12.5 GB RAM. This is not sufficient for my 28 GB 'user_logs' table. To work around this problem, i will read the file in chunks and use a filter to filter out only the customers we are interested in and then concatenate these fltered chunks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MFD1eouvNiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iter_csv = pd.read_csv('user_logs.csv', iterator=True, chunksize=1000)    # you can try with different chunk size\n",
        "user_log = pd.concat([chunk[chunk['msno'].isin(msno)] for chunk in iter_csv])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2Dn1xWjBAfA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8c252c59-c022-4aa7-c988-d3467bfb31da"
      },
      "source": [
        "user_log.to_csv('user_log.csv') \n",
        "files.download('user_log.csv')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_cfabde85-bd10-48ce-ae70-587398abe941\", \"user_log.csv\", 424580070)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewpd7kjTtp0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b4a003e-14c6-4e2f-c674-9907c01428e4"
      },
      "source": [
        "user_logs['msno'].nunique()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1201162"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2p329f14O0h",
        "colab_type": "text"
      },
      "source": [
        "Before we get into data cleaning and modelling, let us understand the task and the daataset and make assumptions if required.\n",
        "\n",
        "The dataset contains an update in November 2017, for simplicity, we will not include this update.\n",
        "\n",
        "Task: Predict the customer churn for the month of March 2017. **We can say that a customer has churned if he/she doesn't make new service subscription transaction within 30 days after the current membership expiration date.**\n",
        "\n",
        "To begin with let us understand the problem and the data. It always helps me in modelling and to avoid silly mistakes.\n",
        "\n",
        "Certain key points:\n",
        "\n",
        "1.   A customer can auto renew the subscription or manually.\n",
        "2.   A customer can cancel the subscription at any time.\n",
        "\n",
        "\n",
        "To be continued....\n",
        "\n"
      ]
    }
  ]
}